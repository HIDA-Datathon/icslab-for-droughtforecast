{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0,'/p/project/training2005/jupyter/kernels/tensorflow_test/lib/python3.6/site-packages')\n",
    "# import tensorflow\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers, Input, Model\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ttd = np.load('redttd10.npy')\n",
    "ptd = np.load('redptd10.npy')\n",
    "ntd = np.load('/p/project/training2005/HZG_Challenge/nao_index_train.npy')\n",
    "\n",
    "ttst = np.load('redttst10.npy')\n",
    "ptst = np.load('redptst10.npy')\n",
    "\n",
    "#plt.plot(range(data.shape[1]),data[0])\n",
    "\n",
    "def _add_layer(dim, input_tensor, activ):\n",
    "    if activ != '':\n",
    "        x = layers.Dense(dim, activation=activ)(input_tensor)\n",
    "    else: \n",
    "        x = layers.Dense(dim)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def dense_cell(dim, input_tensor, activs):\n",
    "    x = _add_layer(dim, input_tensor, activs[0])\n",
    "    for a in activs[1:]:\n",
    "        x = _add_layer(dim,x,a)\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "def cnn_cell(x, ks, st, filters):\n",
    "    x_shortcut = x\n",
    "    x = layers.Conv1D(filters=filters[0], kernel_size=1, strides=st, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(filters=filters[1], kernel_size=ks, strides=1, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(filters=filters[2], kernel_size=1, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(filters=1, kernel_size=1, strides=1, padding='same')(x)\n",
    "#     x = layers.UpSampling1D(size=5)(x)\n",
    "    x = layers.Add()([x,x_shortcut])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def build_model():\n",
    "    inp1 = Input(shape=(5,1))\n",
    "    inp2 = Input(shape=(5,1))\n",
    "    #out = layers.Dense(1)(inp)\n",
    "    \n",
    "    #first branch\n",
    "    cx = cnn_cell(inp1, 2, 1, [32,64,32])\n",
    "    x = dense_cell(512, cx, ['relu']*20 + [''])\n",
    "    \n",
    "    #second branch\n",
    "    cy = cnn_cell(inp2, 2, 1, [32,64,32])\n",
    "    y = dense_cell(512, cy, ['relu']*20 + [''])\n",
    "    \n",
    "    #merge branches\n",
    "    out = layers.Add()([x,y])\n",
    "    out = layers.Flatten()(out)\n",
    "    out = layers.Dense(1)(out)\n",
    "    model = Model([inp1,inp2], out)\n",
    "  \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def train_model(model, params ={'vsplit':0.111,'ne':145,'bs':256}):\n",
    "#     d1 = \n",
    "    history = model.fit([np.reshape(ttd,(ttd.shape[0],ttd.shape[1],1)),\n",
    "                         np.reshape(ptd,(ptd.shape[0],ptd.shape[1],1))], \n",
    "                        np.reshape(ntd,(ntd.shape[0],1)),\n",
    "                        epochs=params['ne'], \n",
    "                        batch_size=params['bs'],\n",
    "                        validation_split=params['vsplit'])\n",
    "    return [model, history]\n",
    "\n",
    "def test_model(model):\n",
    "    return model.predict([ttst,ptst])\n",
    "\n",
    "def plot_losses(epochs, history):\n",
    "    #ks = history.keys()\n",
    "    ks =['loss','val_loss','mean_absolute_error','val_mean_absolute_error']\n",
    "    [plt.plot(range(epochs), history[k],'x-') for k in ks]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 5, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 5, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5, 32)        64          input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 5, 32)        64          input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 5, 32)        128         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 5, 32)        128         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 5, 64)        4160        batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 5, 64)        4160        batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 5, 64)        256         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 5, 64)        256         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 5, 32)        2080        batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 5, 32)        2080        batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 5, 32)        128         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 5, 32)        128         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5, 1)         33          batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5, 1)         33          batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 5, 1)         0           conv1d_52[0][0]                  \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 5, 1)         0           conv1d_56[0][0]                  \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 5, 1)         4           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 5, 1)         4           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_282 (Dense)               (None, 5, 512)       1024        batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_303 (Dense)               (None, 5, 512)       1024        batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 5, 512)       2048        dense_282[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 5, 512)       2048        dense_303[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_283 (Dense)               (None, 5, 512)       262656      batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_304 (Dense)               (None, 5, 512)       262656      batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 5, 512)       2048        dense_283[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 5, 512)       2048        dense_304[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_284 (Dense)               (None, 5, 512)       262656      batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_305 (Dense)               (None, 5, 512)       262656      batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 5, 512)       2048        dense_284[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 5, 512)       2048        dense_305[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_285 (Dense)               (None, 5, 512)       262656      batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_306 (Dense)               (None, 5, 512)       262656      batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 5, 512)       2048        dense_285[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 5, 512)       2048        dense_306[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_286 (Dense)               (None, 5, 512)       262656      batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_307 (Dense)               (None, 5, 512)       262656      batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 5, 512)       2048        dense_286[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 5, 512)       2048        dense_307[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_287 (Dense)               (None, 5, 512)       262656      batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_308 (Dense)               (None, 5, 512)       262656      batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 5, 512)       2048        dense_287[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 5, 512)       2048        dense_308[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_288 (Dense)               (None, 5, 512)       262656      batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_309 (Dense)               (None, 5, 512)       262656      batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 5, 512)       2048        dense_288[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 5, 512)       2048        dense_309[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_289 (Dense)               (None, 5, 512)       262656      batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_310 (Dense)               (None, 5, 512)       262656      batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 5, 512)       2048        dense_289[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 5, 512)       2048        dense_310[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_290 (Dense)               (None, 5, 512)       262656      batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_311 (Dense)               (None, 5, 512)       262656      batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 5, 512)       2048        dense_290[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 5, 512)       2048        dense_311[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_291 (Dense)               (None, 5, 512)       262656      batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_312 (Dense)               (None, 5, 512)       262656      batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 5, 512)       2048        dense_291[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 5, 512)       2048        dense_312[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_292 (Dense)               (None, 5, 512)       262656      batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_313 (Dense)               (None, 5, 512)       262656      batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 5, 512)       2048        dense_292[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 5, 512)       2048        dense_313[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_293 (Dense)               (None, 5, 512)       262656      batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_314 (Dense)               (None, 5, 512)       262656      batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 5, 512)       2048        dense_293[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 5, 512)       2048        dense_314[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_294 (Dense)               (None, 5, 512)       262656      batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_315 (Dense)               (None, 5, 512)       262656      batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 5, 512)       2048        dense_294[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 5, 512)       2048        dense_315[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_295 (Dense)               (None, 5, 512)       262656      batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_316 (Dense)               (None, 5, 512)       262656      batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 5, 512)       2048        dense_295[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 5, 512)       2048        dense_316[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_296 (Dense)               (None, 5, 512)       262656      batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_317 (Dense)               (None, 5, 512)       262656      batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 5, 512)       2048        dense_296[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 5, 512)       2048        dense_317[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_297 (Dense)               (None, 5, 512)       262656      batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_318 (Dense)               (None, 5, 512)       262656      batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 5, 512)       2048        dense_297[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 5, 512)       2048        dense_318[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_298 (Dense)               (None, 5, 512)       262656      batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_319 (Dense)               (None, 5, 512)       262656      batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 5, 512)       2048        dense_298[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 5, 512)       2048        dense_319[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_299 (Dense)               (None, 5, 512)       262656      batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_320 (Dense)               (None, 5, 512)       262656      batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 5, 512)       2048        dense_299[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 5, 512)       2048        dense_320[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_300 (Dense)               (None, 5, 512)       262656      batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_321 (Dense)               (None, 5, 512)       262656      batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 5, 512)       2048        dense_300[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 5, 512)       2048        dense_321[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_301 (Dense)               (None, 5, 512)       262656      batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_322 (Dense)               (None, 5, 512)       262656      batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 5, 512)       2048        dense_301[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 5, 512)       2048        dense_322[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_302 (Dense)               (None, 5, 512)       262656      batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_323 (Dense)               (None, 5, 512)       262656      batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 5, 512)       2048        dense_302[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 5, 512)       2048        dense_323[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 5, 512)       0           batch_normalization_347[0][0]    \n",
      "                                                                 batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 2560)         0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_324 (Dense)               (None, 1)            2561        flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,610,571\n",
      "Trainable params: 10,567,047\n",
      "Non-trainable params: 43,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/1500\n",
      "800/800 [==============================] - 39s 48ms/step - loss: 6.0253 - mean_absolute_error: 1.9554 - val_loss: 7134.2764 - val_mean_absolute_error: 69.5742\n",
      "Epoch 2/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 8.9633 - mean_absolute_error: 2.3615 - val_loss: 4233.2939 - val_mean_absolute_error: 48.4152\n",
      "Epoch 3/1500\n",
      "800/800 [==============================] - 0s 314us/step - loss: 7.3604 - mean_absolute_error: 2.1330 - val_loss: 4501.7588 - val_mean_absolute_error: 51.9067\n",
      "Epoch 4/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 8.4720 - mean_absolute_error: 2.3234 - val_loss: 1449.8486 - val_mean_absolute_error: 28.9278\n",
      "Epoch 5/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 8.2579 - mean_absolute_error: 2.3258 - val_loss: 2297.0950 - val_mean_absolute_error: 37.5187\n",
      "Epoch 6/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 4.2783 - mean_absolute_error: 1.6315 - val_loss: 6386.7104 - val_mean_absolute_error: 62.3734\n",
      "Epoch 7/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 4.8573 - mean_absolute_error: 1.7383 - val_loss: 966.9289 - val_mean_absolute_error: 24.1831\n",
      "Epoch 8/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 3.5655 - mean_absolute_error: 1.5113 - val_loss: 1485.0911 - val_mean_absolute_error: 29.3963\n",
      "Epoch 9/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 2.8952 - mean_absolute_error: 1.3556 - val_loss: 461.0081 - val_mean_absolute_error: 16.4115\n",
      "Epoch 10/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 2.2773 - mean_absolute_error: 1.1627 - val_loss: 1163.7646 - val_mean_absolute_error: 23.9235\n",
      "Epoch 11/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 2.2592 - mean_absolute_error: 1.2099 - val_loss: 114.1339 - val_mean_absolute_error: 8.6801\n",
      "Epoch 12/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 2.1164 - mean_absolute_error: 1.1659 - val_loss: 161.6250 - val_mean_absolute_error: 9.5694\n",
      "Epoch 13/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 1.7100 - mean_absolute_error: 1.0310 - val_loss: 65.8279 - val_mean_absolute_error: 6.3197\n",
      "Epoch 14/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.8377 - mean_absolute_error: 1.0968 - val_loss: 284.1460 - val_mean_absolute_error: 12.3115\n",
      "Epoch 15/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.7411 - mean_absolute_error: 1.0526 - val_loss: 65.9364 - val_mean_absolute_error: 5.9971\n",
      "Epoch 16/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.4881 - mean_absolute_error: 0.9654 - val_loss: 30.3180 - val_mean_absolute_error: 3.9542\n",
      "Epoch 17/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 1.6293 - mean_absolute_error: 1.0145 - val_loss: 53.7287 - val_mean_absolute_error: 5.9051\n",
      "Epoch 18/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.4688 - mean_absolute_error: 0.9388 - val_loss: 34.5069 - val_mean_absolute_error: 4.5147\n",
      "Epoch 19/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.2855 - mean_absolute_error: 0.8938 - val_loss: 20.8873 - val_mean_absolute_error: 3.3324\n",
      "Epoch 20/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.1991 - mean_absolute_error: 0.8589 - val_loss: 25.0195 - val_mean_absolute_error: 3.8484\n",
      "Epoch 21/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.2476 - mean_absolute_error: 0.9022 - val_loss: 11.5033 - val_mean_absolute_error: 2.5921\n",
      "Epoch 22/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.1263 - mean_absolute_error: 0.8456 - val_loss: 9.9137 - val_mean_absolute_error: 2.5200\n",
      "Epoch 23/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.1157 - mean_absolute_error: 0.8226 - val_loss: 5.9645 - val_mean_absolute_error: 2.0040\n",
      "Epoch 24/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 1.1549 - mean_absolute_error: 0.8605 - val_loss: 7.2071 - val_mean_absolute_error: 2.0531\n",
      "Epoch 25/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.3240 - mean_absolute_error: 0.9049 - val_loss: 4.9639 - val_mean_absolute_error: 1.7476\n",
      "Epoch 26/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.2666 - mean_absolute_error: 0.8910 - val_loss: 5.1093 - val_mean_absolute_error: 1.8208\n",
      "Epoch 27/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.3086 - mean_absolute_error: 0.8933 - val_loss: 4.4554 - val_mean_absolute_error: 1.5790\n",
      "Epoch 28/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.2941 - mean_absolute_error: 0.9150 - val_loss: 3.0421 - val_mean_absolute_error: 1.4280\n",
      "Epoch 29/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.0098 - mean_absolute_error: 0.8032 - val_loss: 6.0380 - val_mean_absolute_error: 1.7780\n",
      "Epoch 30/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 1.2603 - mean_absolute_error: 0.8925 - val_loss: 4.2151 - val_mean_absolute_error: 1.6400\n",
      "Epoch 31/1500\n",
      "800/800 [==============================] - 0s 322us/step - loss: 1.1808 - mean_absolute_error: 0.8462 - val_loss: 5.3330 - val_mean_absolute_error: 1.8155\n",
      "Epoch 32/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.1573 - mean_absolute_error: 0.8564 - val_loss: 5.9927 - val_mean_absolute_error: 1.9546\n",
      "Epoch 33/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.0676 - mean_absolute_error: 0.8107 - val_loss: 5.9891 - val_mean_absolute_error: 1.8271\n",
      "Epoch 34/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.2593 - mean_absolute_error: 0.8879 - val_loss: 2.8683 - val_mean_absolute_error: 1.3712\n",
      "Epoch 35/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.0840 - mean_absolute_error: 0.8230 - val_loss: 2.6892 - val_mean_absolute_error: 1.2954\n",
      "Epoch 36/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.9977 - mean_absolute_error: 0.8013 - val_loss: 4.0003 - val_mean_absolute_error: 1.5719\n",
      "Epoch 37/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.9848 - mean_absolute_error: 0.7890 - val_loss: 2.6045 - val_mean_absolute_error: 1.3299\n",
      "Epoch 38/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0166 - mean_absolute_error: 0.7975 - val_loss: 2.8084 - val_mean_absolute_error: 1.4078\n",
      "Epoch 39/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9486 - mean_absolute_error: 0.7734 - val_loss: 3.2084 - val_mean_absolute_error: 1.4870\n",
      "Epoch 40/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9765 - mean_absolute_error: 0.7788 - val_loss: 2.4465 - val_mean_absolute_error: 1.2995\n",
      "Epoch 41/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9355 - mean_absolute_error: 0.7683 - val_loss: 2.7160 - val_mean_absolute_error: 1.3269\n",
      "Epoch 42/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.0445 - mean_absolute_error: 0.8115 - val_loss: 2.1759 - val_mean_absolute_error: 1.2375\n",
      "Epoch 43/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 1.0061 - mean_absolute_error: 0.7971 - val_loss: 2.6248 - val_mean_absolute_error: 1.3472\n",
      "Epoch 44/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.1053 - mean_absolute_error: 0.8159 - val_loss: 2.5933 - val_mean_absolute_error: 1.3281\n",
      "Epoch 45/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.0939 - mean_absolute_error: 0.8263 - val_loss: 2.1129 - val_mean_absolute_error: 1.2048\n",
      "Epoch 46/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9605 - mean_absolute_error: 0.7789 - val_loss: 2.3775 - val_mean_absolute_error: 1.2437\n",
      "Epoch 47/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9349 - mean_absolute_error: 0.7531 - val_loss: 2.5043 - val_mean_absolute_error: 1.2969\n",
      "Epoch 48/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.0000 - mean_absolute_error: 0.7780 - val_loss: 2.1947 - val_mean_absolute_error: 1.2055\n",
      "Epoch 49/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.9994 - mean_absolute_error: 0.7901 - val_loss: 2.3440 - val_mean_absolute_error: 1.2332\n",
      "Epoch 50/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.0671 - mean_absolute_error: 0.8242 - val_loss: 2.3679 - val_mean_absolute_error: 1.1946\n",
      "Epoch 51/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0539 - mean_absolute_error: 0.8007 - val_loss: 1.8547 - val_mean_absolute_error: 1.1057\n",
      "Epoch 52/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0401 - mean_absolute_error: 0.8121 - val_loss: 1.7343 - val_mean_absolute_error: 1.0852\n",
      "Epoch 53/1500\n",
      "800/800 [==============================] - 0s 333us/step - loss: 1.0435 - mean_absolute_error: 0.8033 - val_loss: 1.7781 - val_mean_absolute_error: 1.0939\n",
      "Epoch 54/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.1033 - mean_absolute_error: 0.8238 - val_loss: 1.8700 - val_mean_absolute_error: 1.1269\n",
      "Epoch 55/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.1088 - mean_absolute_error: 0.8385 - val_loss: 2.2192 - val_mean_absolute_error: 1.2473\n",
      "Epoch 56/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 1.1718 - mean_absolute_error: 0.8431 - val_loss: 1.7469 - val_mean_absolute_error: 1.0960\n",
      "Epoch 57/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0540 - mean_absolute_error: 0.8251 - val_loss: 1.6549 - val_mean_absolute_error: 1.0615\n",
      "Epoch 58/1500\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.9294 - mean_absolute_error: 0.7658 - val_loss: 2.0460 - val_mean_absolute_error: 1.1421\n",
      "Epoch 59/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.9491 - mean_absolute_error: 0.7576 - val_loss: 2.0542 - val_mean_absolute_error: 1.1513\n",
      "Epoch 60/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9033 - mean_absolute_error: 0.7505 - val_loss: 2.3845 - val_mean_absolute_error: 1.1906\n",
      "Epoch 61/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9249 - mean_absolute_error: 0.7594 - val_loss: 2.0302 - val_mean_absolute_error: 1.1663\n",
      "Epoch 62/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.9652 - mean_absolute_error: 0.7787 - val_loss: 2.1598 - val_mean_absolute_error: 1.1629\n",
      "Epoch 63/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0557 - mean_absolute_error: 0.8223 - val_loss: 2.1139 - val_mean_absolute_error: 1.2073\n",
      "Epoch 64/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.9902 - mean_absolute_error: 0.8037 - val_loss: 2.0715 - val_mean_absolute_error: 1.2053\n",
      "Epoch 65/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.9107 - mean_absolute_error: 0.7483 - val_loss: 2.2263 - val_mean_absolute_error: 1.2059\n",
      "Epoch 66/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0145 - mean_absolute_error: 0.8000 - val_loss: 2.0611 - val_mean_absolute_error: 1.1973\n",
      "Epoch 67/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9631 - mean_absolute_error: 0.7830 - val_loss: 2.0951 - val_mean_absolute_error: 1.1865\n",
      "Epoch 68/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9795 - mean_absolute_error: 0.7813 - val_loss: 1.8584 - val_mean_absolute_error: 1.1022\n",
      "Epoch 69/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9935 - mean_absolute_error: 0.7889 - val_loss: 1.9314 - val_mean_absolute_error: 1.1623\n",
      "Epoch 70/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9259 - mean_absolute_error: 0.7587 - val_loss: 2.0398 - val_mean_absolute_error: 1.2111\n",
      "Epoch 71/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.9778 - mean_absolute_error: 0.7811 - val_loss: 2.0322 - val_mean_absolute_error: 1.1655\n",
      "Epoch 72/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0235 - mean_absolute_error: 0.8059 - val_loss: 2.0474 - val_mean_absolute_error: 1.1966\n",
      "Epoch 73/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.0846 - mean_absolute_error: 0.8304 - val_loss: 1.9713 - val_mean_absolute_error: 1.1444\n",
      "Epoch 74/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9809 - mean_absolute_error: 0.7971 - val_loss: 2.1045 - val_mean_absolute_error: 1.1500\n",
      "Epoch 75/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9297 - mean_absolute_error: 0.7634 - val_loss: 2.1592 - val_mean_absolute_error: 1.2032\n",
      "Epoch 76/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0715 - mean_absolute_error: 0.8259 - val_loss: 2.1466 - val_mean_absolute_error: 1.2141\n",
      "Epoch 77/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9139 - mean_absolute_error: 0.7534 - val_loss: 2.0358 - val_mean_absolute_error: 1.1567\n",
      "Epoch 78/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9839 - mean_absolute_error: 0.7954 - val_loss: 2.0604 - val_mean_absolute_error: 1.1978\n",
      "Epoch 79/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9192 - mean_absolute_error: 0.7534 - val_loss: 2.5152 - val_mean_absolute_error: 1.3636\n",
      "Epoch 80/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0450 - mean_absolute_error: 0.8029 - val_loss: 2.4558 - val_mean_absolute_error: 1.2696\n",
      "Epoch 81/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 1.1693 - mean_absolute_error: 0.8365 - val_loss: 1.9124 - val_mean_absolute_error: 1.1166\n",
      "Epoch 82/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9271 - mean_absolute_error: 0.7520 - val_loss: 2.4531 - val_mean_absolute_error: 1.2834\n",
      "Epoch 83/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0132 - mean_absolute_error: 0.7942 - val_loss: 2.0555 - val_mean_absolute_error: 1.1620\n",
      "Epoch 84/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0035 - mean_absolute_error: 0.7901 - val_loss: 2.0253 - val_mean_absolute_error: 1.1572\n",
      "Epoch 85/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 1.0278 - mean_absolute_error: 0.8216 - val_loss: 2.0901 - val_mean_absolute_error: 1.2002\n",
      "Epoch 86/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0016 - mean_absolute_error: 0.7809 - val_loss: 2.0259 - val_mean_absolute_error: 1.1497\n",
      "Epoch 87/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9733 - mean_absolute_error: 0.7756 - val_loss: 1.8862 - val_mean_absolute_error: 1.1463\n",
      "Epoch 88/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8673 - mean_absolute_error: 0.7325 - val_loss: 2.0564 - val_mean_absolute_error: 1.1903\n",
      "Epoch 89/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9771 - mean_absolute_error: 0.7704 - val_loss: 1.9526 - val_mean_absolute_error: 1.1454\n",
      "Epoch 90/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0525 - mean_absolute_error: 0.8214 - val_loss: 1.8293 - val_mean_absolute_error: 1.1086\n",
      "Epoch 91/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9598 - mean_absolute_error: 0.7588 - val_loss: 2.1489 - val_mean_absolute_error: 1.2343\n",
      "Epoch 92/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.0116 - mean_absolute_error: 0.7858 - val_loss: 2.0654 - val_mean_absolute_error: 1.2175\n",
      "Epoch 93/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 1.0096 - mean_absolute_error: 0.7948 - val_loss: 2.1435 - val_mean_absolute_error: 1.1836\n",
      "Epoch 94/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.0438 - mean_absolute_error: 0.8064 - val_loss: 1.8046 - val_mean_absolute_error: 1.0902\n",
      "Epoch 95/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0617 - mean_absolute_error: 0.8004 - val_loss: 1.9358 - val_mean_absolute_error: 1.1541\n",
      "Epoch 96/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.1642 - mean_absolute_error: 0.8622 - val_loss: 1.8550 - val_mean_absolute_error: 1.1103\n",
      "Epoch 97/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0294 - mean_absolute_error: 0.8027 - val_loss: 1.8218 - val_mean_absolute_error: 1.0880\n",
      "Epoch 98/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9775 - mean_absolute_error: 0.7910 - val_loss: 2.3780 - val_mean_absolute_error: 1.2310\n",
      "Epoch 99/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0986 - mean_absolute_error: 0.8146 - val_loss: 2.1082 - val_mean_absolute_error: 1.2241\n",
      "Epoch 100/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.0359 - mean_absolute_error: 0.7953 - val_loss: 1.7033 - val_mean_absolute_error: 1.0650\n",
      "Epoch 101/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.9460 - mean_absolute_error: 0.7748 - val_loss: 1.5786 - val_mean_absolute_error: 1.0183\n",
      "Epoch 102/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9483 - mean_absolute_error: 0.7678 - val_loss: 1.7782 - val_mean_absolute_error: 1.0884\n",
      "Epoch 103/1500\n",
      "800/800 [==============================] - 0s 319us/step - loss: 0.9985 - mean_absolute_error: 0.7844 - val_loss: 2.9058 - val_mean_absolute_error: 1.3368\n",
      "Epoch 104/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.1228 - mean_absolute_error: 0.8267 - val_loss: 1.8029 - val_mean_absolute_error: 1.1313\n",
      "Epoch 105/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0792 - mean_absolute_error: 0.8356 - val_loss: 1.8218 - val_mean_absolute_error: 1.1229\n",
      "Epoch 106/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.1081 - mean_absolute_error: 0.8121 - val_loss: 1.8095 - val_mean_absolute_error: 1.0854\n",
      "Epoch 107/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.1430 - mean_absolute_error: 0.8543 - val_loss: 1.8418 - val_mean_absolute_error: 1.1339\n",
      "Epoch 108/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.1228 - mean_absolute_error: 0.8107 - val_loss: 2.3053 - val_mean_absolute_error: 1.2467\n",
      "Epoch 109/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0372 - mean_absolute_error: 0.8027 - val_loss: 1.7863 - val_mean_absolute_error: 1.0969\n",
      "Epoch 110/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9641 - mean_absolute_error: 0.7931 - val_loss: 1.8333 - val_mean_absolute_error: 1.0895\n",
      "Epoch 111/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.9395 - mean_absolute_error: 0.7661 - val_loss: 1.9685 - val_mean_absolute_error: 1.1291\n",
      "Epoch 112/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8854 - mean_absolute_error: 0.7495 - val_loss: 1.9526 - val_mean_absolute_error: 1.1185\n",
      "Epoch 113/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9148 - mean_absolute_error: 0.7678 - val_loss: 1.9501 - val_mean_absolute_error: 1.1053\n",
      "Epoch 114/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9613 - mean_absolute_error: 0.7801 - val_loss: 1.6647 - val_mean_absolute_error: 1.0822\n",
      "Epoch 115/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9623 - mean_absolute_error: 0.7859 - val_loss: 1.9112 - val_mean_absolute_error: 1.1528\n",
      "Epoch 116/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9253 - mean_absolute_error: 0.7624 - val_loss: 2.2486 - val_mean_absolute_error: 1.1896\n",
      "Epoch 117/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9286 - mean_absolute_error: 0.7528 - val_loss: 1.9915 - val_mean_absolute_error: 1.1570\n",
      "Epoch 118/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.8960 - mean_absolute_error: 0.7439 - val_loss: 1.7552 - val_mean_absolute_error: 1.0682\n",
      "Epoch 119/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9772 - mean_absolute_error: 0.7786 - val_loss: 1.7836 - val_mean_absolute_error: 1.0839\n",
      "Epoch 120/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.9183 - mean_absolute_error: 0.7500 - val_loss: 1.9205 - val_mean_absolute_error: 1.1452\n",
      "Epoch 121/1500\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.9269 - mean_absolute_error: 0.7772 - val_loss: 1.8515 - val_mean_absolute_error: 1.1277\n",
      "Epoch 122/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.8968 - mean_absolute_error: 0.7553 - val_loss: 1.7946 - val_mean_absolute_error: 1.0990\n",
      "Epoch 123/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.8945 - mean_absolute_error: 0.7582 - val_loss: 1.7439 - val_mean_absolute_error: 1.0943\n",
      "Epoch 124/1500\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.8932 - mean_absolute_error: 0.7501 - val_loss: 1.8002 - val_mean_absolute_error: 1.1069\n",
      "Epoch 125/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9377 - mean_absolute_error: 0.7644 - val_loss: 1.8513 - val_mean_absolute_error: 1.1410\n",
      "Epoch 126/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9727 - mean_absolute_error: 0.7954 - val_loss: 1.9657 - val_mean_absolute_error: 1.1615\n",
      "Epoch 127/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9319 - mean_absolute_error: 0.7437 - val_loss: 1.9787 - val_mean_absolute_error: 1.1726\n",
      "Epoch 128/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9524 - mean_absolute_error: 0.7711 - val_loss: 1.7584 - val_mean_absolute_error: 1.1144\n",
      "Epoch 129/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9054 - mean_absolute_error: 0.7638 - val_loss: 1.9629 - val_mean_absolute_error: 1.1364\n",
      "Epoch 130/1500\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.9013 - mean_absolute_error: 0.7578 - val_loss: 1.9198 - val_mean_absolute_error: 1.1522\n",
      "Epoch 131/1500\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.9444 - mean_absolute_error: 0.7712 - val_loss: 2.0116 - val_mean_absolute_error: 1.1903\n",
      "Epoch 132/1500\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.9718 - mean_absolute_error: 0.7752 - val_loss: 1.8047 - val_mean_absolute_error: 1.1383\n",
      "Epoch 133/1500\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.9919 - mean_absolute_error: 0.7951 - val_loss: 1.9356 - val_mean_absolute_error: 1.1557\n",
      "Epoch 134/1500\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.9744 - mean_absolute_error: 0.7982 - val_loss: 1.7883 - val_mean_absolute_error: 1.1362\n",
      "Epoch 135/1500\n",
      "800/800 [==============================] - 0s 272us/step - loss: 0.9383 - mean_absolute_error: 0.7723 - val_loss: 1.8180 - val_mean_absolute_error: 1.1413\n",
      "Epoch 136/1500\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.8794 - mean_absolute_error: 0.7412 - val_loss: 1.8374 - val_mean_absolute_error: 1.1413\n",
      "Epoch 137/1500\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.8952 - mean_absolute_error: 0.7552 - val_loss: 1.8469 - val_mean_absolute_error: 1.1242\n",
      "Epoch 138/1500\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.8578 - mean_absolute_error: 0.7292 - val_loss: 1.6951 - val_mean_absolute_error: 1.0870\n",
      "Epoch 139/1500\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.8714 - mean_absolute_error: 0.7449 - val_loss: 1.7912 - val_mean_absolute_error: 1.1385\n",
      "Epoch 140/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8597 - mean_absolute_error: 0.7360 - val_loss: 1.9833 - val_mean_absolute_error: 1.1742\n",
      "Epoch 141/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.9083 - mean_absolute_error: 0.7602 - val_loss: 2.0097 - val_mean_absolute_error: 1.1682\n",
      "Epoch 142/1500\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.8908 - mean_absolute_error: 0.7443 - val_loss: 1.7422 - val_mean_absolute_error: 1.0890\n",
      "Epoch 143/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9491 - mean_absolute_error: 0.7809 - val_loss: 1.7654 - val_mean_absolute_error: 1.1003\n",
      "Epoch 144/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8939 - mean_absolute_error: 0.7598 - val_loss: 1.9042 - val_mean_absolute_error: 1.1212\n",
      "Epoch 145/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.8771 - mean_absolute_error: 0.7483 - val_loss: 1.7555 - val_mean_absolute_error: 1.1248\n",
      "Epoch 146/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8595 - mean_absolute_error: 0.7347 - val_loss: 1.7092 - val_mean_absolute_error: 1.1015\n",
      "Epoch 147/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8793 - mean_absolute_error: 0.7426 - val_loss: 1.8471 - val_mean_absolute_error: 1.1394\n",
      "Epoch 148/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8470 - mean_absolute_error: 0.7332 - val_loss: 1.8116 - val_mean_absolute_error: 1.1452\n",
      "Epoch 149/1500\n",
      "800/800 [==============================] - 0s 324us/step - loss: 0.8004 - mean_absolute_error: 0.7040 - val_loss: 1.8151 - val_mean_absolute_error: 1.1366\n",
      "Epoch 150/1500\n",
      "800/800 [==============================] - 0s 321us/step - loss: 0.8120 - mean_absolute_error: 0.7124 - val_loss: 2.0178 - val_mean_absolute_error: 1.1479\n",
      "Epoch 151/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8921 - mean_absolute_error: 0.7537 - val_loss: 1.8769 - val_mean_absolute_error: 1.1268\n",
      "Epoch 152/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.9096 - mean_absolute_error: 0.7549 - val_loss: 1.8901 - val_mean_absolute_error: 1.1546\n",
      "Epoch 153/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8882 - mean_absolute_error: 0.7475 - val_loss: 1.6872 - val_mean_absolute_error: 1.0701\n",
      "Epoch 154/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.9244 - mean_absolute_error: 0.7622 - val_loss: 1.7849 - val_mean_absolute_error: 1.0830\n",
      "Epoch 155/1500\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.8934 - mean_absolute_error: 0.7490 - val_loss: 1.7913 - val_mean_absolute_error: 1.1416\n",
      "Epoch 156/1500\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.9366 - mean_absolute_error: 0.7737 - val_loss: 1.7426 - val_mean_absolute_error: 1.1085\n",
      "Epoch 157/1500\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.8946 - mean_absolute_error: 0.7526 - val_loss: 1.7344 - val_mean_absolute_error: 1.1160\n",
      "Epoch 158/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8704 - mean_absolute_error: 0.7381 - val_loss: 1.7942 - val_mean_absolute_error: 1.1358\n",
      "Epoch 159/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.9316 - mean_absolute_error: 0.7552 - val_loss: 1.8648 - val_mean_absolute_error: 1.1480\n",
      "Epoch 160/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9219 - mean_absolute_error: 0.7674 - val_loss: 2.0060 - val_mean_absolute_error: 1.1716\n",
      "Epoch 161/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.9200 - mean_absolute_error: 0.7568 - val_loss: 1.9346 - val_mean_absolute_error: 1.1908\n",
      "Epoch 162/1500\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.9041 - mean_absolute_error: 0.7486 - val_loss: 1.9161 - val_mean_absolute_error: 1.1916\n",
      "Epoch 163/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.9866 - mean_absolute_error: 0.7721 - val_loss: 2.1101 - val_mean_absolute_error: 1.2164\n",
      "Epoch 164/1500\n",
      "800/800 [==============================] - 0s 320us/step - loss: 1.1886 - mean_absolute_error: 0.8403 - val_loss: 2.0363 - val_mean_absolute_error: 1.1973\n",
      "Epoch 165/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 1.1633 - mean_absolute_error: 0.8397 - val_loss: 2.1535 - val_mean_absolute_error: 1.2436\n",
      "Epoch 166/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 1.0107 - mean_absolute_error: 0.7804 - val_loss: 1.7742 - val_mean_absolute_error: 1.1317\n",
      "Epoch 167/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.9414 - mean_absolute_error: 0.7460 - val_loss: 1.8954 - val_mean_absolute_error: 1.1255\n",
      "Epoch 168/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 1.0188 - mean_absolute_error: 0.8008 - val_loss: 1.8538 - val_mean_absolute_error: 1.1248\n",
      "Epoch 169/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.9740 - mean_absolute_error: 0.7802 - val_loss: 1.8463 - val_mean_absolute_error: 1.1483\n",
      "Epoch 170/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9643 - mean_absolute_error: 0.7654 - val_loss: 1.8433 - val_mean_absolute_error: 1.1271\n",
      "Epoch 171/1500\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.9860 - mean_absolute_error: 0.7864 - val_loss: 1.6273 - val_mean_absolute_error: 1.0595\n",
      "Epoch 172/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.9453 - mean_absolute_error: 0.7825 - val_loss: 1.7730 - val_mean_absolute_error: 1.1058\n",
      "Epoch 173/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.9122 - mean_absolute_error: 0.7554 - val_loss: 1.9717 - val_mean_absolute_error: 1.1487\n",
      "Epoch 174/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9777 - mean_absolute_error: 0.7941 - val_loss: 1.7849 - val_mean_absolute_error: 1.1157\n",
      "Epoch 175/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.9484 - mean_absolute_error: 0.7739 - val_loss: 1.8928 - val_mean_absolute_error: 1.1296\n",
      "Epoch 176/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9453 - mean_absolute_error: 0.7790 - val_loss: 2.0980 - val_mean_absolute_error: 1.1624\n",
      "Epoch 177/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9319 - mean_absolute_error: 0.7702 - val_loss: 1.9690 - val_mean_absolute_error: 1.1392\n",
      "Epoch 178/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9891 - mean_absolute_error: 0.7941 - val_loss: 1.8306 - val_mean_absolute_error: 1.0776\n",
      "Epoch 179/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 1.0924 - mean_absolute_error: 0.8197 - val_loss: 1.8533 - val_mean_absolute_error: 1.0957\n",
      "Epoch 180/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9570 - mean_absolute_error: 0.7959 - val_loss: 2.0473 - val_mean_absolute_error: 1.1940\n",
      "Epoch 181/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 1.0482 - mean_absolute_error: 0.8218 - val_loss: 2.0002 - val_mean_absolute_error: 1.1747\n",
      "Epoch 182/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.9837 - mean_absolute_error: 0.7887 - val_loss: 1.7081 - val_mean_absolute_error: 1.0925\n",
      "Epoch 183/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.9948 - mean_absolute_error: 0.7919 - val_loss: 1.6076 - val_mean_absolute_error: 1.0478\n",
      "Epoch 184/1500\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.9124 - mean_absolute_error: 0.7638 - val_loss: 1.7314 - val_mean_absolute_error: 1.0817\n",
      "Epoch 185/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.9401 - mean_absolute_error: 0.7629 - val_loss: 1.7511 - val_mean_absolute_error: 1.1076\n",
      "Epoch 186/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8970 - mean_absolute_error: 0.7424 - val_loss: 1.9181 - val_mean_absolute_error: 1.1550\n",
      "Epoch 187/1500\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.8595 - mean_absolute_error: 0.7312 - val_loss: 1.8894 - val_mean_absolute_error: 1.1371\n",
      "Epoch 188/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.8669 - mean_absolute_error: 0.7446 - val_loss: 2.0772 - val_mean_absolute_error: 1.1958\n",
      "Epoch 189/1500\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.9025 - mean_absolute_error: 0.7586 - val_loss: 1.8458 - val_mean_absolute_error: 1.0997\n",
      "Epoch 190/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8911 - mean_absolute_error: 0.7431 - val_loss: 1.8432 - val_mean_absolute_error: 1.1079\n",
      "Epoch 191/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8468 - mean_absolute_error: 0.7257 - val_loss: 1.8858 - val_mean_absolute_error: 1.1194\n",
      "Epoch 192/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8768 - mean_absolute_error: 0.7279 - val_loss: 1.9755 - val_mean_absolute_error: 1.1640\n",
      "Epoch 193/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8162 - mean_absolute_error: 0.7126 - val_loss: 1.9111 - val_mean_absolute_error: 1.1401\n",
      "Epoch 194/1500\n",
      "800/800 [==============================] - 0s 330us/step - loss: 0.8558 - mean_absolute_error: 0.7354 - val_loss: 1.9135 - val_mean_absolute_error: 1.1392\n",
      "Epoch 195/1500\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.8156 - mean_absolute_error: 0.7118 - val_loss: 1.9401 - val_mean_absolute_error: 1.1412\n",
      "Epoch 196/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8231 - mean_absolute_error: 0.7122 - val_loss: 1.8491 - val_mean_absolute_error: 1.1510\n",
      "Epoch 197/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.8245 - mean_absolute_error: 0.7231 - val_loss: 1.8426 - val_mean_absolute_error: 1.1436\n",
      "Epoch 198/1500\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.8534 - mean_absolute_error: 0.7317 - val_loss: 1.9307 - val_mean_absolute_error: 1.1498\n",
      "Epoch 199/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.9008 - mean_absolute_error: 0.7439 - val_loss: 1.9148 - val_mean_absolute_error: 1.1299\n",
      "Epoch 200/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8779 - mean_absolute_error: 0.7454 - val_loss: 1.9310 - val_mean_absolute_error: 1.1454\n",
      "Epoch 201/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8199 - mean_absolute_error: 0.7199 - val_loss: 1.8829 - val_mean_absolute_error: 1.1413\n",
      "Epoch 202/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8085 - mean_absolute_error: 0.7137 - val_loss: 1.8490 - val_mean_absolute_error: 1.1217\n",
      "Epoch 203/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8588 - mean_absolute_error: 0.7273 - val_loss: 1.8298 - val_mean_absolute_error: 1.1043\n",
      "Epoch 204/1500\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.8203 - mean_absolute_error: 0.7258 - val_loss: 1.8538 - val_mean_absolute_error: 1.1185\n",
      "Epoch 205/1500\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.8142 - mean_absolute_error: 0.7147 - val_loss: 1.7216 - val_mean_absolute_error: 1.0757\n",
      "Epoch 206/1500\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.8821 - mean_absolute_error: 0.7373 - val_loss: 1.8400 - val_mean_absolute_error: 1.1332\n",
      "Epoch 207/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.9360 - mean_absolute_error: 0.7657 - val_loss: 1.7582 - val_mean_absolute_error: 1.1115\n",
      "Epoch 208/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.8727 - mean_absolute_error: 0.7345 - val_loss: 1.8195 - val_mean_absolute_error: 1.1333\n",
      "Epoch 209/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.8338 - mean_absolute_error: 0.7042 - val_loss: 1.8382 - val_mean_absolute_error: 1.1251\n",
      "Epoch 210/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8834 - mean_absolute_error: 0.7383 - val_loss: 1.9665 - val_mean_absolute_error: 1.1396\n",
      "Epoch 211/1500\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.8568 - mean_absolute_error: 0.7419 - val_loss: 1.9801 - val_mean_absolute_error: 1.1334\n",
      "Epoch 212/1500\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.8753 - mean_absolute_error: 0.7423 - val_loss: 1.8465 - val_mean_absolute_error: 1.1184\n",
      "Epoch 213/1500\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.8310 - mean_absolute_error: 0.7163 - val_loss: 1.8839 - val_mean_absolute_error: 1.1327\n",
      "Epoch 214/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9240 - mean_absolute_error: 0.7486 - val_loss: 1.8831 - val_mean_absolute_error: 1.1222\n",
      "Epoch 215/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.9240 - mean_absolute_error: 0.7646 - val_loss: 1.7299 - val_mean_absolute_error: 1.0639\n",
      "Epoch 216/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.9324 - mean_absolute_error: 0.7629 - val_loss: 1.7267 - val_mean_absolute_error: 1.0606\n",
      "Epoch 217/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.8669 - mean_absolute_error: 0.7365 - val_loss: 1.5937 - val_mean_absolute_error: 1.0351\n",
      "Epoch 218/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8387 - mean_absolute_error: 0.7266 - val_loss: 1.5892 - val_mean_absolute_error: 1.0416\n",
      "Epoch 219/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9424 - mean_absolute_error: 0.7657 - val_loss: 1.7766 - val_mean_absolute_error: 1.1110\n",
      "Epoch 220/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.8958 - mean_absolute_error: 0.7441 - val_loss: 1.7599 - val_mean_absolute_error: 1.0768\n",
      "Epoch 221/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9610 - mean_absolute_error: 0.7730 - val_loss: 1.7080 - val_mean_absolute_error: 1.0831\n",
      "Epoch 222/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.8521 - mean_absolute_error: 0.7201 - val_loss: 1.7362 - val_mean_absolute_error: 1.1066\n",
      "Epoch 223/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.8763 - mean_absolute_error: 0.7300 - val_loss: 1.8397 - val_mean_absolute_error: 1.1150\n",
      "Epoch 224/1500\n",
      "800/800 [==============================] - 0s 301us/step - loss: 0.8467 - mean_absolute_error: 0.7279 - val_loss: 1.9320 - val_mean_absolute_error: 1.1433\n",
      "Epoch 225/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8658 - mean_absolute_error: 0.7383 - val_loss: 1.7558 - val_mean_absolute_error: 1.1050\n",
      "Epoch 226/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.8369 - mean_absolute_error: 0.7355 - val_loss: 1.6327 - val_mean_absolute_error: 1.0701\n",
      "Epoch 227/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8796 - mean_absolute_error: 0.7401 - val_loss: 1.7239 - val_mean_absolute_error: 1.0922\n",
      "Epoch 228/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8533 - mean_absolute_error: 0.7313 - val_loss: 1.6494 - val_mean_absolute_error: 1.0421\n",
      "Epoch 229/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.7782 - mean_absolute_error: 0.6979 - val_loss: 1.6071 - val_mean_absolute_error: 1.0399\n",
      "Epoch 230/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.8354 - mean_absolute_error: 0.7227 - val_loss: 1.7546 - val_mean_absolute_error: 1.0742\n",
      "Epoch 231/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.8049 - mean_absolute_error: 0.7081 - val_loss: 1.8297 - val_mean_absolute_error: 1.1171\n",
      "Epoch 232/1500\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.7886 - mean_absolute_error: 0.7075 - val_loss: 1.9252 - val_mean_absolute_error: 1.1317\n",
      "Epoch 233/1500\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.8208 - mean_absolute_error: 0.7252 - val_loss: 1.9124 - val_mean_absolute_error: 1.1493\n",
      "Epoch 234/1500\n",
      "800/800 [==============================] - 0s 318us/step - loss: 0.8202 - mean_absolute_error: 0.7216 - val_loss: 1.8399 - val_mean_absolute_error: 1.1186\n",
      "Epoch 235/1500\n",
      "800/800 [==============================] - 0s 320us/step - loss: 0.9135 - mean_absolute_error: 0.7655 - val_loss: 1.6515 - val_mean_absolute_error: 1.0666\n",
      "Epoch 236/1500\n",
      "800/800 [==============================] - 0s 322us/step - loss: 0.9248 - mean_absolute_error: 0.7604 - val_loss: 1.6923 - val_mean_absolute_error: 1.0745\n",
      "Epoch 237/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 1.0446 - mean_absolute_error: 0.8141 - val_loss: 1.6077 - val_mean_absolute_error: 1.0573\n",
      "Epoch 238/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.9344 - mean_absolute_error: 0.7712 - val_loss: 1.5957 - val_mean_absolute_error: 1.0348\n",
      "Epoch 239/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8554 - mean_absolute_error: 0.7265 - val_loss: 1.6865 - val_mean_absolute_error: 1.0676\n",
      "Epoch 240/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8492 - mean_absolute_error: 0.7199 - val_loss: 1.7227 - val_mean_absolute_error: 1.0997\n",
      "Epoch 241/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9192 - mean_absolute_error: 0.7776 - val_loss: 1.7122 - val_mean_absolute_error: 1.1096\n",
      "Epoch 242/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8390 - mean_absolute_error: 0.7236 - val_loss: 1.9594 - val_mean_absolute_error: 1.1357\n",
      "Epoch 243/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.8916 - mean_absolute_error: 0.7478 - val_loss: 1.8811 - val_mean_absolute_error: 1.1210\n",
      "Epoch 244/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.8986 - mean_absolute_error: 0.7481 - val_loss: 1.6973 - val_mean_absolute_error: 1.0731\n",
      "Epoch 245/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8807 - mean_absolute_error: 0.7456 - val_loss: 1.8840 - val_mean_absolute_error: 1.1252\n",
      "Epoch 246/1500\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.8760 - mean_absolute_error: 0.7442 - val_loss: 1.9857 - val_mean_absolute_error: 1.1722\n",
      "Epoch 247/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.8882 - mean_absolute_error: 0.7527 - val_loss: 1.9818 - val_mean_absolute_error: 1.1720\n",
      "Epoch 248/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.8885 - mean_absolute_error: 0.7435 - val_loss: 2.1270 - val_mean_absolute_error: 1.1735\n",
      "Epoch 249/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.8738 - mean_absolute_error: 0.7468 - val_loss: 2.1429 - val_mean_absolute_error: 1.1800\n",
      "Epoch 250/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.9569 - mean_absolute_error: 0.7865 - val_loss: 1.9754 - val_mean_absolute_error: 1.1300\n",
      "Epoch 251/1500\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.9055 - mean_absolute_error: 0.7643 - val_loss: 2.1481 - val_mean_absolute_error: 1.2139\n",
      "Epoch 252/1500\n",
      "800/800 [==============================] - 0s 312us/step - loss: 0.8614 - mean_absolute_error: 0.7327 - val_loss: 1.9824 - val_mean_absolute_error: 1.1787\n",
      "Epoch 253/1500\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.8488 - mean_absolute_error: 0.7262 - val_loss: 1.9312 - val_mean_absolute_error: 1.1317\n",
      "Epoch 254/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8449 - mean_absolute_error: 0.7338 - val_loss: 1.8931 - val_mean_absolute_error: 1.1274\n",
      "Epoch 255/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8882 - mean_absolute_error: 0.7459 - val_loss: 1.7088 - val_mean_absolute_error: 1.0653\n",
      "Epoch 256/1500\n",
      "800/800 [==============================] - 0s 317us/step - loss: 0.8217 - mean_absolute_error: 0.7215 - val_loss: 1.7214 - val_mean_absolute_error: 1.0497\n",
      "Epoch 257/1500\n",
      "800/800 [==============================] - 0s 305us/step - loss: 0.8291 - mean_absolute_error: 0.7171 - val_loss: 1.6387 - val_mean_absolute_error: 1.0446\n",
      "Epoch 258/1500\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.8106 - mean_absolute_error: 0.7117 - val_loss: 1.7913 - val_mean_absolute_error: 1.1008\n",
      "Epoch 259/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.8198 - mean_absolute_error: 0.7167 - val_loss: 1.8166 - val_mean_absolute_error: 1.1133\n",
      "Epoch 260/1500\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.8078 - mean_absolute_error: 0.7058 - val_loss: 1.8641 - val_mean_absolute_error: 1.1520\n",
      "Epoch 261/1500\n",
      "800/800 [==============================] - 0s 314us/step - loss: 0.8575 - mean_absolute_error: 0.7303 - val_loss: 1.7988 - val_mean_absolute_error: 1.1390\n",
      "Epoch 262/1500\n",
      "800/800 [==============================] - 0s 309us/step - loss: 0.8486 - mean_absolute_error: 0.7268 - val_loss: 1.7765 - val_mean_absolute_error: 1.1407\n",
      "Epoch 263/1500\n",
      "800/800 [==============================] - 0s 311us/step - loss: 0.8458 - mean_absolute_error: 0.7258 - val_loss: 1.8011 - val_mean_absolute_error: 1.1324\n",
      "Epoch 264/1500\n",
      "800/800 [==============================] - 0s 315us/step - loss: 0.7867 - mean_absolute_error: 0.6902 - val_loss: 1.7218 - val_mean_absolute_error: 1.1037\n",
      "Epoch 265/1500\n",
      "800/800 [==============================] - 0s 304us/step - loss: 0.8138 - mean_absolute_error: 0.7166 - val_loss: 1.6971 - val_mean_absolute_error: 1.0572\n",
      "Epoch 266/1500\n",
      "800/800 [==============================] - 0s 308us/step - loss: 0.8404 - mean_absolute_error: 0.7141 - val_loss: 1.8624 - val_mean_absolute_error: 1.1309\n",
      "Epoch 267/1500\n",
      "256/800 [========>.....................] - ETA: 0s - loss: 0.9128 - mean_absolute_error: 0.7593"
     ]
    }
   ],
   "source": [
    "model,loss = train_model(model, params ={'vsplit':0.111,'ne':250,'bs':256})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(1500,loss.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "datathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
