{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0,'/p/project/training2005/jupyter/kernels/tensorflow_test/lib/python3.6/site-packages')\n",
    "# import tensorflow\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers, Input, Model\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ttd = np.reshape(np.load('/p/project/training2005/HZG_Challenge/tas_train.npy'),(900,54,43))\n",
    "ptd = np.reshape(np.load('/p/project/training2005/HZG_Challenge/tas_train.npy'),(900,54,43))\n",
    "ntd = np.load('/p/project/training2005/HZG_Challenge/nao_index_train.npy')\n",
    "\n",
    "ttst = np.reshape(np.load('/p/project/training2005/HZG_Challenge/tas_train.npy'),(900,54,43))\n",
    "ptst = np.reshape(np.load('/p/project/training2005/HZG_Challenge/tas_train.npy'),(900,54,43))\n",
    "\n",
    "#plt.plot(range(data.shape[1]),data[0])\n",
    "\n",
    "def _add_layer(dim, input_tensor, activ):\n",
    "    if activ != '':\n",
    "        x = layers.Dense(dim, activation=activ)(input_tensor)\n",
    "    else: \n",
    "        x = layers.Dense(dim)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def dense_cell(dim, input_tensor, activs):\n",
    "    x = _add_layer(dim, input_tensor, activs[0])\n",
    "    for a in activs[1:]:\n",
    "        x = _add_layer(dim,x,a)\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "def cnn_cell(x, ks, st, filters):\n",
    "    x_shortcut = x\n",
    "    x = layers.Conv2D(filters=filters[0], kernel_size=1, strides=st, activation='relu', padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Conv2D(filters=filters[1], kernel_size=ks, strides=1, activation='relu', padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Conv2D(filters=filters[2], kernel_size=1, strides=1, padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters=1, kernel_size=1, strides=1, padding='same')(x)\n",
    "#     x = layers.UpSampling1D(size=5)(x)\n",
    "    x = layers.Add()([x,x_shortcut])\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def build_model():\n",
    "    inp1 = Input(shape=(54,43,1))\n",
    "    inp2 = Input(shape=(54,43,1))\n",
    "    #out = layers.Dense(1)(inp)\n",
    "    \n",
    "    #first branch\n",
    "    cx = cnn_cell(inp1, 2, 1, [2,2,2])\n",
    "    x = dense_cell(10, cx, ['relu']*2 + [''])\n",
    "    \n",
    "    #second branch\n",
    "    cy = cnn_cell(inp2, 2, 1, [2,2,2])\n",
    "    y = dense_cell(10, cy, ['relu']*2 + [''])\n",
    "    \n",
    "    #merge branches\n",
    "    out = layers.Add()([x,y])\n",
    "    out = layers.Flatten()(out)\n",
    "    out = layers.Dense(1)(out)\n",
    "    model = Model([inp1,inp2], out)\n",
    "  \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def train_model(model, params ={'vsplit':0.111,'ne':145,'bs':128}):\n",
    "#     d1 = \n",
    "    history = model.fit([np.reshape(ttd,(ttd.shape[0],ttd.shape[1],1)),\n",
    "                         np.reshape(ptd,(ptd.shape[0],ptd.shape[1],1))], \n",
    "                        np.reshape(ntd,(ntd.shape[0],1)),\n",
    "                        epochs=params['ne'], \n",
    "                        batch_size=params['bs'],\n",
    "                        validation_split=params['vsplit'])\n",
    "    return [model, history]\n",
    "\n",
    "def test_model(model):\n",
    "    return model.predict([ttst,ptst])\n",
    "\n",
    "def plot_losses(epochs, history):\n",
    "    #ks = history.keys()\n",
    "    ks =['loss','val_loss','mean_absolute_error','val_mean_absolute_error']\n",
    "    [plt.plot(range(epochs), history[k],'x-') for k in ks]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-671884cecb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b0323f91f779>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#first branch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#second branch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b0323f91f779>\u001b[0m in \u001b[0;36mdense_cell\u001b[0;34m(dim, input_tensor, activs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdense_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b0323f91f779>\u001b[0m in \u001b[0;36m_add_layer\u001b[0;34m(dim, input_tensor, activ)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/Keras/2.2.4-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/Keras/2.2.4-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    183\u001b[0m         normed_training, mean, variance = K.normalize_batch_in_training(\n\u001b[1;32m    184\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             epsilon=self.epsilon)\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/Keras/2.2.4-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mnormalize_batch_in_training\u001b[0;34m(x, gamma, beta, reduction_axes, epsilon)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \"\"\"\n\u001b[1;32m   1857\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_has_nchw_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m             return _broadcast_normalize_batch_in_training(x, gamma, beta,\n\u001b[1;32m   1860\u001b[0m                                                           \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/Keras/2.2.4-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_has_nchw_support\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m    291\u001b[0m     \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_current_explicit_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mgpus_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpus_available\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/Keras/2.2.4-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/Keras/2.2.4-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    185\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/jusuf/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/145\n",
      "800/800 [==============================] - 32s 41ms/step - loss: 6.5359 - mean_absolute_error: 2.0194 - val_loss: 38154.1641 - val_mean_absolute_error: 174.0265\n",
      "Epoch 2/145\n",
      "800/800 [==============================] - 0s 263us/step - loss: 11.3648 - mean_absolute_error: 2.4789 - val_loss: 27931.8047 - val_mean_absolute_error: 139.4791\n",
      "Epoch 3/145\n",
      "800/800 [==============================] - 0s 254us/step - loss: 19.1361 - mean_absolute_error: 3.4130 - val_loss: 3392.5613 - val_mean_absolute_error: 44.1350\n",
      "Epoch 4/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 6.9136 - mean_absolute_error: 2.1239 - val_loss: 2320.3662 - val_mean_absolute_error: 38.0422\n",
      "Epoch 5/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 6.7775 - mean_absolute_error: 2.0814 - val_loss: 10400.9561 - val_mean_absolute_error: 80.2364\n",
      "Epoch 6/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 4.4201 - mean_absolute_error: 1.6626 - val_loss: 5372.8394 - val_mean_absolute_error: 53.9993\n",
      "Epoch 7/145\n",
      "800/800 [==============================] - 0s 254us/step - loss: 4.7362 - mean_absolute_error: 1.7278 - val_loss: 3534.4597 - val_mean_absolute_error: 48.8648\n",
      "Epoch 8/145\n",
      "800/800 [==============================] - 0s 257us/step - loss: 3.1005 - mean_absolute_error: 1.3996 - val_loss: 2540.4329 - val_mean_absolute_error: 40.8976\n",
      "Epoch 9/145\n",
      "800/800 [==============================] - 0s 251us/step - loss: 3.2840 - mean_absolute_error: 1.4478 - val_loss: 1596.9672 - val_mean_absolute_error: 28.3923\n",
      "Epoch 10/145\n",
      "800/800 [==============================] - 0s 257us/step - loss: 2.5759 - mean_absolute_error: 1.2791 - val_loss: 973.5567 - val_mean_absolute_error: 24.2523\n",
      "Epoch 11/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 2.1596 - mean_absolute_error: 1.1707 - val_loss: 492.6099 - val_mean_absolute_error: 16.4364\n",
      "Epoch 12/145\n",
      "800/800 [==============================] - 0s 260us/step - loss: 1.9503 - mean_absolute_error: 1.1179 - val_loss: 466.7003 - val_mean_absolute_error: 16.1665\n",
      "Epoch 13/145\n",
      "800/800 [==============================] - 0s 254us/step - loss: 1.8012 - mean_absolute_error: 1.0693 - val_loss: 130.6334 - val_mean_absolute_error: 8.1630\n",
      "Epoch 14/145\n",
      "800/800 [==============================] - 0s 253us/step - loss: 1.6455 - mean_absolute_error: 1.0221 - val_loss: 61.3319 - val_mean_absolute_error: 5.6055\n",
      "Epoch 15/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.4851 - mean_absolute_error: 0.9798 - val_loss: 33.2758 - val_mean_absolute_error: 4.3647\n",
      "Epoch 16/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.5241 - mean_absolute_error: 0.9863 - val_loss: 30.6178 - val_mean_absolute_error: 4.1411\n",
      "Epoch 17/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.6900 - mean_absolute_error: 1.0299 - val_loss: 15.9028 - val_mean_absolute_error: 2.9220\n",
      "Epoch 18/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.5663 - mean_absolute_error: 1.0109 - val_loss: 10.2576 - val_mean_absolute_error: 2.4249\n",
      "Epoch 19/145\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.4937 - mean_absolute_error: 0.9641 - val_loss: 11.2509 - val_mean_absolute_error: 2.3410\n",
      "Epoch 20/145\n",
      "800/800 [==============================] - 0s 253us/step - loss: 1.4513 - mean_absolute_error: 0.9599 - val_loss: 22.3788 - val_mean_absolute_error: 3.0292\n",
      "Epoch 21/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.2433 - mean_absolute_error: 0.8984 - val_loss: 20.8736 - val_mean_absolute_error: 3.5076\n",
      "Epoch 22/145\n",
      "800/800 [==============================] - 0s 257us/step - loss: 1.5318 - mean_absolute_error: 0.9704 - val_loss: 24.3845 - val_mean_absolute_error: 3.3760\n",
      "Epoch 23/145\n",
      "800/800 [==============================] - 0s 253us/step - loss: 1.4094 - mean_absolute_error: 0.9402 - val_loss: 8.4115 - val_mean_absolute_error: 2.0773\n",
      "Epoch 24/145\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.4474 - mean_absolute_error: 0.9602 - val_loss: 6.3541 - val_mean_absolute_error: 1.9452\n",
      "Epoch 25/145\n",
      "800/800 [==============================] - 0s 261us/step - loss: 1.4875 - mean_absolute_error: 0.9307 - val_loss: 14.8375 - val_mean_absolute_error: 2.4286\n",
      "Epoch 26/145\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.4577 - mean_absolute_error: 0.9518 - val_loss: 4.9912 - val_mean_absolute_error: 1.5596\n",
      "Epoch 27/145\n",
      "800/800 [==============================] - 0s 254us/step - loss: 1.1535 - mean_absolute_error: 0.8469 - val_loss: 12.2467 - val_mean_absolute_error: 2.4471\n",
      "Epoch 28/145\n",
      "800/800 [==============================] - 0s 250us/step - loss: 1.1438 - mean_absolute_error: 0.8356 - val_loss: 3.2974 - val_mean_absolute_error: 1.4032\n",
      "Epoch 29/145\n",
      "800/800 [==============================] - 0s 263us/step - loss: 1.1909 - mean_absolute_error: 0.8760 - val_loss: 2.3411 - val_mean_absolute_error: 1.2599\n",
      "Epoch 30/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.2557 - mean_absolute_error: 0.8750 - val_loss: 3.1202 - val_mean_absolute_error: 1.3671\n",
      "Epoch 31/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.2122 - mean_absolute_error: 0.8805 - val_loss: 2.2541 - val_mean_absolute_error: 1.1809\n",
      "Epoch 32/145\n",
      "800/800 [==============================] - 0s 250us/step - loss: 1.0931 - mean_absolute_error: 0.8364 - val_loss: 2.2625 - val_mean_absolute_error: 1.2025\n",
      "Epoch 33/145\n",
      "800/800 [==============================] - 0s 261us/step - loss: 1.1319 - mean_absolute_error: 0.8505 - val_loss: 2.3099 - val_mean_absolute_error: 1.1934\n",
      "Epoch 34/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.1518 - mean_absolute_error: 0.8624 - val_loss: 3.1596 - val_mean_absolute_error: 1.4250\n",
      "Epoch 35/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.1312 - mean_absolute_error: 0.8389 - val_loss: 3.3909 - val_mean_absolute_error: 1.4738\n",
      "Epoch 36/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.0688 - mean_absolute_error: 0.8429 - val_loss: 2.3815 - val_mean_absolute_error: 1.2299\n",
      "Epoch 37/145\n",
      "800/800 [==============================] - 0s 253us/step - loss: 1.0564 - mean_absolute_error: 0.8268 - val_loss: 3.6686 - val_mean_absolute_error: 1.4117\n",
      "Epoch 38/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.9909 - mean_absolute_error: 0.7876 - val_loss: 2.6550 - val_mean_absolute_error: 1.3068\n",
      "Epoch 39/145\n",
      "800/800 [==============================] - 0s 251us/step - loss: 1.1533 - mean_absolute_error: 0.8386 - val_loss: 4.1634 - val_mean_absolute_error: 1.4434\n",
      "Epoch 40/145\n",
      "800/800 [==============================] - 0s 253us/step - loss: 1.2824 - mean_absolute_error: 0.8975 - val_loss: 2.4788 - val_mean_absolute_error: 1.2945\n",
      "Epoch 41/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.1555 - mean_absolute_error: 0.8569 - val_loss: 2.0292 - val_mean_absolute_error: 1.1220\n",
      "Epoch 42/145\n",
      "800/800 [==============================] - 0s 252us/step - loss: 1.1697 - mean_absolute_error: 0.8360 - val_loss: 2.2305 - val_mean_absolute_error: 1.1724\n",
      "Epoch 43/145\n",
      "800/800 [==============================] - 0s 249us/step - loss: 1.1170 - mean_absolute_error: 0.8547 - val_loss: 1.6556 - val_mean_absolute_error: 1.0228\n",
      "Epoch 44/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.0806 - mean_absolute_error: 0.8239 - val_loss: 1.7409 - val_mean_absolute_error: 1.0607\n",
      "Epoch 45/145\n",
      "800/800 [==============================] - 0s 256us/step - loss: 1.1731 - mean_absolute_error: 0.8751 - val_loss: 1.7510 - val_mean_absolute_error: 1.1140\n",
      "Epoch 46/145\n",
      "800/800 [==============================] - 0s 255us/step - loss: 1.1915 - mean_absolute_error: 0.8668 - val_loss: 1.9687 - val_mean_absolute_error: 1.1016\n",
      "Epoch 47/145\n",
      "800/800 [==============================] - 0s 268us/step - loss: 1.1043 - mean_absolute_error: 0.8398 - val_loss: 2.0603 - val_mean_absolute_error: 1.1481\n",
      "Epoch 48/145\n",
      "800/800 [==============================] - 0s 291us/step - loss: 1.1084 - mean_absolute_error: 0.8390 - val_loss: 2.3090 - val_mean_absolute_error: 1.2278\n",
      "Epoch 49/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.2378 - mean_absolute_error: 0.8829 - val_loss: 1.7420 - val_mean_absolute_error: 1.0670\n",
      "Epoch 50/145\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.1272 - mean_absolute_error: 0.8305 - val_loss: 2.1287 - val_mean_absolute_error: 1.1508\n",
      "Epoch 51/145\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.4088 - mean_absolute_error: 0.9326 - val_loss: 1.7794 - val_mean_absolute_error: 1.0836\n",
      "Epoch 52/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.1641 - mean_absolute_error: 0.8698 - val_loss: 1.7438 - val_mean_absolute_error: 1.0631\n",
      "Epoch 53/145\n",
      "800/800 [==============================] - 0s 304us/step - loss: 1.1204 - mean_absolute_error: 0.8427 - val_loss: 2.0809 - val_mean_absolute_error: 1.1409\n",
      "Epoch 54/145\n",
      "800/800 [==============================] - 0s 281us/step - loss: 1.2816 - mean_absolute_error: 0.8970 - val_loss: 1.9949 - val_mean_absolute_error: 1.1552\n",
      "Epoch 55/145\n",
      "800/800 [==============================] - 0s 298us/step - loss: 1.3358 - mean_absolute_error: 0.9179 - val_loss: 1.7649 - val_mean_absolute_error: 1.0483\n",
      "Epoch 56/145\n",
      "800/800 [==============================] - 0s 285us/step - loss: 1.1189 - mean_absolute_error: 0.8416 - val_loss: 2.1294 - val_mean_absolute_error: 1.1476\n",
      "Epoch 57/145\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.0113 - mean_absolute_error: 0.7986 - val_loss: 2.1509 - val_mean_absolute_error: 1.2092\n",
      "Epoch 58/145\n",
      "800/800 [==============================] - 0s 302us/step - loss: 1.1088 - mean_absolute_error: 0.8488 - val_loss: 2.3120 - val_mean_absolute_error: 1.2373\n",
      "Epoch 59/145\n",
      "800/800 [==============================] - 0s 281us/step - loss: 1.1372 - mean_absolute_error: 0.8472 - val_loss: 1.7743 - val_mean_absolute_error: 1.0974\n",
      "Epoch 60/145\n",
      "800/800 [==============================] - 0s 303us/step - loss: 1.1448 - mean_absolute_error: 0.8628 - val_loss: 1.7831 - val_mean_absolute_error: 1.0895\n",
      "Epoch 61/145\n",
      "800/800 [==============================] - 0s 283us/step - loss: 1.2153 - mean_absolute_error: 0.8874 - val_loss: 1.8691 - val_mean_absolute_error: 1.0879\n",
      "Epoch 62/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.2409 - mean_absolute_error: 0.8693 - val_loss: 1.7107 - val_mean_absolute_error: 1.0195\n",
      "Epoch 63/145\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.1309 - mean_absolute_error: 0.8281 - val_loss: 1.6565 - val_mean_absolute_error: 1.0460\n",
      "Epoch 64/145\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.1032 - mean_absolute_error: 0.8263 - val_loss: 1.6576 - val_mean_absolute_error: 1.0324\n",
      "Epoch 65/145\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.0483 - mean_absolute_error: 0.8207 - val_loss: 1.8057 - val_mean_absolute_error: 1.0112\n",
      "Epoch 66/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.0106 - mean_absolute_error: 0.8015 - val_loss: 1.5057 - val_mean_absolute_error: 0.9712\n",
      "Epoch 67/145\n",
      "800/800 [==============================] - 0s 283us/step - loss: 1.0699 - mean_absolute_error: 0.8328 - val_loss: 1.8116 - val_mean_absolute_error: 1.0441\n",
      "Epoch 68/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.1422 - mean_absolute_error: 0.8460 - val_loss: 1.5121 - val_mean_absolute_error: 1.0203\n",
      "Epoch 69/145\n",
      "800/800 [==============================] - 0s 282us/step - loss: 0.9645 - mean_absolute_error: 0.7847 - val_loss: 1.6052 - val_mean_absolute_error: 1.0393\n",
      "Epoch 70/145\n",
      "800/800 [==============================] - 0s 280us/step - loss: 1.0007 - mean_absolute_error: 0.8009 - val_loss: 1.7153 - val_mean_absolute_error: 1.0463\n",
      "Epoch 71/145\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.0510 - mean_absolute_error: 0.8086 - val_loss: 1.9514 - val_mean_absolute_error: 1.0945\n",
      "Epoch 72/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.1690 - mean_absolute_error: 0.8584 - val_loss: 2.0274 - val_mean_absolute_error: 1.1222\n",
      "Epoch 73/145\n",
      "800/800 [==============================] - 0s 281us/step - loss: 1.0670 - mean_absolute_error: 0.8202 - val_loss: 2.0956 - val_mean_absolute_error: 1.1697\n",
      "Epoch 74/145\n",
      "800/800 [==============================] - 0s 283us/step - loss: 1.1904 - mean_absolute_error: 0.8521 - val_loss: 2.7290 - val_mean_absolute_error: 1.2805\n",
      "Epoch 75/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.3483 - mean_absolute_error: 0.8878 - val_loss: 1.6433 - val_mean_absolute_error: 1.0346\n",
      "Epoch 76/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.1567 - mean_absolute_error: 0.8681 - val_loss: 1.5684 - val_mean_absolute_error: 0.9833\n",
      "Epoch 77/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.1401 - mean_absolute_error: 0.8360 - val_loss: 1.5454 - val_mean_absolute_error: 0.9947\n",
      "Epoch 78/145\n",
      "800/800 [==============================] - 0s 301us/step - loss: 1.1535 - mean_absolute_error: 0.8416 - val_loss: 1.5034 - val_mean_absolute_error: 1.0333\n",
      "Epoch 79/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.0678 - mean_absolute_error: 0.8306 - val_loss: 1.7677 - val_mean_absolute_error: 1.0858\n",
      "Epoch 80/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.0717 - mean_absolute_error: 0.8323 - val_loss: 1.6265 - val_mean_absolute_error: 1.0756\n",
      "Epoch 81/145\n",
      "800/800 [==============================] - 0s 291us/step - loss: 1.2473 - mean_absolute_error: 0.8952 - val_loss: 1.5503 - val_mean_absolute_error: 0.9939\n",
      "Epoch 82/145\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0953 - mean_absolute_error: 0.8379 - val_loss: 1.6080 - val_mean_absolute_error: 0.9909\n",
      "Epoch 83/145\n",
      "800/800 [==============================] - 0s 296us/step - loss: 1.0727 - mean_absolute_error: 0.8286 - val_loss: 1.3531 - val_mean_absolute_error: 0.9529\n",
      "Epoch 84/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0197 - mean_absolute_error: 0.7963 - val_loss: 1.6212 - val_mean_absolute_error: 1.0301\n",
      "Epoch 85/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0583 - mean_absolute_error: 0.8266 - val_loss: 1.7110 - val_mean_absolute_error: 1.0633\n",
      "Epoch 86/145\n",
      "800/800 [==============================] - 0s 283us/step - loss: 1.0707 - mean_absolute_error: 0.8215 - val_loss: 1.9237 - val_mean_absolute_error: 1.0883\n",
      "Epoch 87/145\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.9894 - mean_absolute_error: 0.7963 - val_loss: 1.7376 - val_mean_absolute_error: 1.0450\n",
      "Epoch 88/145\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.0377 - mean_absolute_error: 0.8030 - val_loss: 1.5209 - val_mean_absolute_error: 0.9789\n",
      "Epoch 89/145\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0345 - mean_absolute_error: 0.8252 - val_loss: 1.5016 - val_mean_absolute_error: 0.9836\n",
      "Epoch 90/145\n",
      "800/800 [==============================] - 0s 339us/step - loss: 1.0030 - mean_absolute_error: 0.7927 - val_loss: 1.6945 - val_mean_absolute_error: 1.0516\n",
      "Epoch 91/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.0382 - mean_absolute_error: 0.8102 - val_loss: 1.5540 - val_mean_absolute_error: 1.0259\n",
      "Epoch 92/145\n",
      "800/800 [==============================] - 0s 298us/step - loss: 0.9819 - mean_absolute_error: 0.8054 - val_loss: 1.7516 - val_mean_absolute_error: 1.0863\n",
      "Epoch 93/145\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.9723 - mean_absolute_error: 0.7897 - val_loss: 1.6163 - val_mean_absolute_error: 1.0279\n",
      "Epoch 94/145\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.9971 - mean_absolute_error: 0.8014 - val_loss: 1.7586 - val_mean_absolute_error: 1.0571\n",
      "Epoch 95/145\n",
      "800/800 [==============================] - 0s 310us/step - loss: 1.0843 - mean_absolute_error: 0.8197 - val_loss: 1.6006 - val_mean_absolute_error: 1.0342\n",
      "Epoch 96/145\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.0166 - mean_absolute_error: 0.8106 - val_loss: 1.5768 - val_mean_absolute_error: 1.0021\n",
      "Epoch 97/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.0149 - mean_absolute_error: 0.8045 - val_loss: 1.8620 - val_mean_absolute_error: 1.0896\n",
      "Epoch 98/145\n",
      "800/800 [==============================] - 0s 285us/step - loss: 1.1822 - mean_absolute_error: 0.8573 - val_loss: 1.5598 - val_mean_absolute_error: 1.0074\n",
      "Epoch 99/145\n",
      "800/800 [==============================] - 0s 292us/step - loss: 1.0355 - mean_absolute_error: 0.8034 - val_loss: 1.6209 - val_mean_absolute_error: 1.0525\n",
      "Epoch 100/145\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.0711 - mean_absolute_error: 0.8305 - val_loss: 1.6446 - val_mean_absolute_error: 1.0538\n",
      "Epoch 101/145\n",
      "800/800 [==============================] - 0s 308us/step - loss: 1.0415 - mean_absolute_error: 0.8174 - val_loss: 1.5544 - val_mean_absolute_error: 1.0123\n",
      "Epoch 102/145\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.1424 - mean_absolute_error: 0.8465 - val_loss: 1.6059 - val_mean_absolute_error: 1.0381\n",
      "Epoch 103/145\n",
      "800/800 [==============================] - 0s 282us/step - loss: 1.0668 - mean_absolute_error: 0.8245 - val_loss: 1.7533 - val_mean_absolute_error: 1.0694\n",
      "Epoch 104/145\n",
      "800/800 [==============================] - 0s 281us/step - loss: 1.0648 - mean_absolute_error: 0.8314 - val_loss: 1.6656 - val_mean_absolute_error: 1.0554\n",
      "Epoch 105/145\n",
      "800/800 [==============================] - 0s 291us/step - loss: 1.1224 - mean_absolute_error: 0.8457 - val_loss: 1.4294 - val_mean_absolute_error: 0.9899\n",
      "Epoch 106/145\n",
      "800/800 [==============================] - 0s 292us/step - loss: 1.0045 - mean_absolute_error: 0.8004 - val_loss: 1.7474 - val_mean_absolute_error: 1.0526\n",
      "Epoch 107/145\n",
      "800/800 [==============================] - 0s 306us/step - loss: 1.0491 - mean_absolute_error: 0.8002 - val_loss: 1.8597 - val_mean_absolute_error: 1.1076\n",
      "Epoch 108/145\n",
      "800/800 [==============================] - 0s 296us/step - loss: 1.1124 - mean_absolute_error: 0.8362 - val_loss: 1.8416 - val_mean_absolute_error: 1.0972\n",
      "Epoch 109/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0921 - mean_absolute_error: 0.8145 - val_loss: 1.3897 - val_mean_absolute_error: 0.9754\n",
      "Epoch 110/145\n",
      "800/800 [==============================] - 0s 294us/step - loss: 1.0316 - mean_absolute_error: 0.8095 - val_loss: 1.5069 - val_mean_absolute_error: 0.9872\n",
      "Epoch 111/145\n",
      "800/800 [==============================] - 0s 305us/step - loss: 1.0238 - mean_absolute_error: 0.8035 - val_loss: 1.7438 - val_mean_absolute_error: 1.0601\n",
      "Epoch 112/145\n",
      "800/800 [==============================] - 0s 293us/step - loss: 1.0144 - mean_absolute_error: 0.8033 - val_loss: 1.7060 - val_mean_absolute_error: 1.0508\n",
      "Epoch 113/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.0356 - mean_absolute_error: 0.7976 - val_loss: 1.5096 - val_mean_absolute_error: 1.0124\n",
      "Epoch 114/145\n",
      "800/800 [==============================] - 0s 292us/step - loss: 0.9359 - mean_absolute_error: 0.7612 - val_loss: 1.5013 - val_mean_absolute_error: 1.0177\n",
      "Epoch 115/145\n",
      "800/800 [==============================] - 0s 292us/step - loss: 1.0205 - mean_absolute_error: 0.8066 - val_loss: 1.5027 - val_mean_absolute_error: 1.0057\n",
      "Epoch 116/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.9549 - mean_absolute_error: 0.7718 - val_loss: 1.4783 - val_mean_absolute_error: 0.9859\n",
      "Epoch 117/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.9830 - mean_absolute_error: 0.7953 - val_loss: 1.4873 - val_mean_absolute_error: 0.9935\n",
      "Epoch 118/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0180 - mean_absolute_error: 0.7958 - val_loss: 1.5330 - val_mean_absolute_error: 1.0251\n",
      "Epoch 119/145\n",
      "800/800 [==============================] - 0s 302us/step - loss: 1.0159 - mean_absolute_error: 0.8063 - val_loss: 1.5407 - val_mean_absolute_error: 1.0384\n",
      "Epoch 120/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.9904 - mean_absolute_error: 0.7893 - val_loss: 1.4591 - val_mean_absolute_error: 0.9745\n",
      "Epoch 121/145\n",
      "800/800 [==============================] - 0s 307us/step - loss: 0.9744 - mean_absolute_error: 0.7867 - val_loss: 1.4424 - val_mean_absolute_error: 0.9804\n",
      "Epoch 122/145\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.9677 - mean_absolute_error: 0.7850 - val_loss: 1.4727 - val_mean_absolute_error: 1.0021\n",
      "Epoch 123/145\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.9911 - mean_absolute_error: 0.7947 - val_loss: 1.5090 - val_mean_absolute_error: 1.0022\n",
      "Epoch 124/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0333 - mean_absolute_error: 0.7943 - val_loss: 1.6073 - val_mean_absolute_error: 1.0295\n",
      "Epoch 125/145\n",
      "800/800 [==============================] - 0s 281us/step - loss: 1.0479 - mean_absolute_error: 0.8079 - val_loss: 1.6829 - val_mean_absolute_error: 1.0308\n",
      "Epoch 126/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.0318 - mean_absolute_error: 0.7980 - val_loss: 1.5157 - val_mean_absolute_error: 0.9838\n",
      "Epoch 127/145\n",
      "800/800 [==============================] - 0s 284us/step - loss: 1.0614 - mean_absolute_error: 0.8122 - val_loss: 1.5429 - val_mean_absolute_error: 1.0135\n",
      "Epoch 128/145\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.9907 - mean_absolute_error: 0.7900 - val_loss: 1.4369 - val_mean_absolute_error: 0.9798\n",
      "Epoch 129/145\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.9367 - mean_absolute_error: 0.7685 - val_loss: 1.4919 - val_mean_absolute_error: 0.9875\n",
      "Epoch 130/145\n",
      "800/800 [==============================] - 0s 294us/step - loss: 0.9512 - mean_absolute_error: 0.7821 - val_loss: 1.3897 - val_mean_absolute_error: 0.9376\n",
      "Epoch 131/145\n",
      "800/800 [==============================] - 0s 289us/step - loss: 1.0052 - mean_absolute_error: 0.7995 - val_loss: 1.3725 - val_mean_absolute_error: 0.9491\n",
      "Epoch 132/145\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.0043 - mean_absolute_error: 0.8089 - val_loss: 1.4680 - val_mean_absolute_error: 0.9787\n",
      "Epoch 133/145\n",
      "800/800 [==============================] - 0s 290us/step - loss: 1.1571 - mean_absolute_error: 0.8540 - val_loss: 1.8348 - val_mean_absolute_error: 1.0703\n",
      "Epoch 134/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 1.0810 - mean_absolute_error: 0.8060 - val_loss: 1.4928 - val_mean_absolute_error: 1.0112\n",
      "Epoch 135/145\n",
      "800/800 [==============================] - 0s 294us/step - loss: 1.0786 - mean_absolute_error: 0.8382 - val_loss: 1.6472 - val_mean_absolute_error: 1.0290\n",
      "Epoch 136/145\n",
      "800/800 [==============================] - 0s 294us/step - loss: 1.1351 - mean_absolute_error: 0.8382 - val_loss: 1.5593 - val_mean_absolute_error: 1.0157\n",
      "Epoch 137/145\n",
      "800/800 [==============================] - 0s 294us/step - loss: 1.0725 - mean_absolute_error: 0.8304 - val_loss: 1.4760 - val_mean_absolute_error: 1.0120\n",
      "Epoch 138/145\n",
      "800/800 [==============================] - 0s 311us/step - loss: 1.0419 - mean_absolute_error: 0.8126 - val_loss: 1.6509 - val_mean_absolute_error: 1.0162\n",
      "Epoch 139/145\n",
      "800/800 [==============================] - 0s 298us/step - loss: 1.0774 - mean_absolute_error: 0.8257 - val_loss: 1.5455 - val_mean_absolute_error: 1.0268\n",
      "Epoch 140/145\n",
      "800/800 [==============================] - 0s 287us/step - loss: 1.0019 - mean_absolute_error: 0.7943 - val_loss: 1.4277 - val_mean_absolute_error: 1.0035\n",
      "Epoch 141/145\n",
      "800/800 [==============================] - 0s 306us/step - loss: 0.9649 - mean_absolute_error: 0.7998 - val_loss: 1.5050 - val_mean_absolute_error: 0.9921\n",
      "Epoch 142/145\n",
      "800/800 [==============================] - 0s 291us/step - loss: 0.9612 - mean_absolute_error: 0.7806 - val_loss: 1.4107 - val_mean_absolute_error: 0.9660\n",
      "Epoch 143/145\n",
      "800/800 [==============================] - 0s 293us/step - loss: 0.9548 - mean_absolute_error: 0.7807 - val_loss: 1.3125 - val_mean_absolute_error: 0.9313\n",
      "Epoch 144/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.9720 - mean_absolute_error: 0.7732 - val_loss: 1.3648 - val_mean_absolute_error: 0.9351\n",
      "Epoch 145/145\n",
      "800/800 [==============================] - 0s 288us/step - loss: 0.9678 - mean_absolute_error: 0.7889 - val_loss: 1.5030 - val_mean_absolute_error: 0.9608\n"
     ]
    }
   ],
   "source": [
    "model,loss = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(145,loss.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "datathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
